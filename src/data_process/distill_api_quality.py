import json
import os
from openai import OpenAI
from tqdm import tqdm
import concurrent.futures

# ================= é…ç½®åŒº =================
API_KEY = ""
BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
MODEL_NAME = "deepseek-v3-2-251201"

INPUT_FILE = "data/processed/wuji_chunks.jsonl"
OUTPUT_FILE = "data/processed/train_dataset_final_quality.json"

# ä»…ä¿ç•™æˆå¹´åçš„æ ¸å¿ƒäººç‰©ï¼Œæ’é™¤çˆ¶è¾ˆäººç‰©ï¼ˆå¦‚è°¢é€Šæ—©æœŸã€å¼ ä¸‰ä¸°æ—©æœŸï¼‰
TARGET_ROLES = ["èµµæ•", "å‘¨èŠ·è‹¥", "å°æ˜­", "æ®·ç¦»", "æ¨é€", "éŸ¦ä¸€ç¬‘", "èŒƒé¥", "ç­ç»", "æˆæ˜†", "é¹¿æ–å®¢", "é¹¤ç¬”ç¿", "æœ±å…ƒç’‹"]

# ç¡¬æ€§é»‘åå•ï¼šå¦‚æœ Output é‡Œå‡ºç°è¿™äº›è¯ï¼Œç›´æ¥è§†ä¸ºè„æ•°æ®ä¸¢å¼ƒ
BLACKLIST_WORDS = ["å¼ ç¿ å±±", "ç¿ å±±", "äº”å¼Ÿ", "ç´ ç´ ", "æ®·ç´ ç´ ", "äº”å“¥", "æ©å¸ˆ", "éƒ­è¥„"]
# =========================================

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

def extract_quality_dialogue(chunk_text):
    """
    ä½¿ç”¨æä¸¥è‹›çš„ Prompt æå–æ•°æ®
    """
    prompt = f"""
    ä»»åŠ¡ï¼šä»ã€Šå€šå¤©å± é¾™è®°ã€‹ç‰‡æ®µä¸­æå–ã€æˆå¹´å¼ æ— å¿Œã€‘ï¼ˆæ˜æ•™æ•™ä¸»æ—¶æœŸï¼‰çš„å¯¹è¯ã€‚
    
    âŒ ä¸¥ç¦æå–ä»¥ä¸‹å†…å®¹ï¼ˆè´Ÿé¢çº¦æŸï¼‰ï¼š
    1. ä¸¥ç¦æå–å¼ ç¿ å±±ï¼ˆçˆ¶äº²ï¼‰ã€æ®·ç´ ç´ ï¼ˆæ¯äº²ï¼‰çš„å¯¹è¯ã€‚
    2. ä¸¥ç¦æå–ç«¥å¹´/å°‘å¹´æ—¶æœŸçš„å¯¹è¯ï¼ˆå¦‚å†°ç«å²›æ—¶æœŸã€è´è¶è°·æ—¶æœŸï¼‰ã€‚
    3. ä¸¥ç¦æå–æ—ç™½ã€å¿ƒç†æ´»åŠ¨ã€åŠ¨ä½œæå†™ï¼Œåªæå–â€œå£è¯­â€ã€‚
    4. ä¸¥ç¦è§’è‰²äº’æ¢ï¼ˆInstructionå¿…é¡»æ˜¯ä»–äººï¼ŒOutputå¿…é¡»æ˜¯å¼ æ— å¿Œï¼‰ã€‚

    âœ… æå–æ ¼å¼è¦æ±‚ï¼š
    1. è¿”å› JSON Listã€‚
    2. "instruction": å¯¹æ–¹çš„åå­— + å†’å· + å¯¹æ–¹è¯´çš„è¯ (ä¾‹å¦‚ "èµµæ•ï¼š...")
    3. "output": å¼ æ— å¿Œè¯´çš„è¯ (ä¸è¦å¸¦ "å¼ æ— å¿Œé“ï¼š", ç›´æ¥å†™å†…å®¹)

    å°è¯´ç‰‡æ®µï¼š
    {chunk_text}
    """
    
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„æ•°æ®æ¸…æ´—ä¸“å®¶ã€‚ç»ä¸æå–é”™è¯¯çš„çˆ¶è¾ˆå‰§æƒ…ã€‚"},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.3 # é™ä½æ¸©åº¦ï¼Œè®©æ¨¡å‹æ›´ä¿å®ˆã€æ›´å¬è¯
        )
        data = json.loads(response.choices[0].message.content)
        
        # å…¼å®¹æ€§å¤„ç†
        results = []
        if isinstance(data, dict):
            for key, val in data.items():
                if isinstance(val, list): results = val
        elif isinstance(data, list):
            results = data
            
        return results
    except:
        return []

def process_chunk(chunk):
    text = chunk['text']
    
    # 1. é¢„è¿‡æ»¤ï¼šå¦‚æœæ²¡æœ‰æ ¸å¿ƒäººç‰©ï¼Œå¤§æ¦‚ç‡ä¸æ˜¯æˆ‘ä»¬è¦çš„æ•™ä¸»å‰§æƒ…
    # (è¿™èƒ½å¸®æˆ‘ä»¬è¿‡æ»¤æ‰å¤§é‡å¼ ç¿ å±±æ—¶æœŸçš„å‰§æƒ…ï¼Œå› ä¸ºé‚£æ—¶å€™èµµæ•å‘¨èŠ·è‹¥è¿˜æ²¡å‡ºç”Ÿ)
    if not any(role in text for role in TARGET_ROLES):
        return []
    
    raw_items = extract_quality_dialogue(text)
    
    clean_items = []
    for item in raw_items:
        instr = item.get("instruction", "").strip()
        out = item.get("output", "").strip()
        
        # 2. Python ç¡¬è§„åˆ™æ¸…æ´—
        if len(instr) < 3 or len(out) < 2: continue
        
        # æ£€æŸ¥ Output æ˜¯å¦åŒ…å«çˆ¶è¾ˆé»‘åå•è¯æ±‡ (å¦‚ "æˆ‘æ˜¯ç¿ å±±")
        if any(bad_word in out for bad_word in BLACKLIST_WORDS):
            continue
        
        # æ£€æŸ¥ Instruction æ˜¯å¦åŒ…å«å¼ æ— å¿Œ (é˜²æ­¢æ— å¿Œè‡ªè¨€è‡ªè¯­è¢«å½•å…¥)
        if "æ— å¿Œ" in instr or "æ•™ä¸»" in instr:
             # å¦‚æœ Instruction æ˜¯â€œæ— å¿Œé“ï¼š...â€ï¼Œè¿™è¯´æ˜æå–åäº†ï¼Œä¸¢å¼ƒ
             if "é“" in instr or "è¯´" in instr:
                 continue

        # æ£€æŸ¥ Output æ˜¯å¦åŒ…å«ä»–äººåå­— (é˜²æ­¢è§’è‰²äº’æ¢)
        # ä¾‹å¦‚ Output: "èµµæ•ç¬‘é“..." -> é”™
        if any(role in out for role in ["èµµæ•", "èŠ·è‹¥", "å°æ˜­", "æ¨é€"]):
             if "é“" in out or "è¯´" in out:
                 continue

        clean_items.append({
            "instruction": instr,
            "input": "",
            "output": out,
            "system": "ä½ ç°åœ¨æ˜¯å¼ æ— å¿Œï¼Œè¯·ä»¥æ˜æ•™æ•™ä¸»çš„èº«ä»½ï¼Œç”¨æ­¦ä¾ é£æ ¼å›ç­”ã€‚"
        })
        
    return clean_items

def main():
    print(f"ğŸš€ å¯åŠ¨ç»ˆæè´¨é‡æå– (DeepSeek V3)...")
    
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        all_chunks = [json.loads(line) for line in f]
    
    # å…¨é‡æ‰«æ (æ—¢ç„¶ä½ æœ‰APIï¼Œæˆ‘ä»¬å°±è·‘å…¨ä¸€ç‚¹ï¼Œä¿è¯æ•°é‡)
    # è¿™é‡Œçš„ filter ä¼šè¿‡æ»¤æ‰å¤§æ¦‚ 60% çš„éæ ¸å¿ƒå‰§æƒ…ç‰‡æ®µ
    print(f"ğŸ“‚ å¾…æ‰«æç‰‡æ®µæ± : {len(all_chunks)} ä¸ª")
    
    final_data = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
        futures = [executor.submit(process_chunk, chunk) for chunk in all_chunks]
        
        pbar = tqdm(total=len(futures), desc="âš¡ï¸ æå–ä¸­")
        for future in concurrent.futures.as_completed(futures):
            results = future.result()
            if results:
                final_data.extend(results)
                pbar.set_postfix({"âœ… é«˜è´¨é‡æ¡ç›®": len(final_data)})
            pbar.update(1)
            
    # ä¿å­˜
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
        
    print("="*50)
    print(f"ğŸ‰ æå–ç»“æŸï¼")
    print(f"   æœ€ç»ˆæ•°æ®é›†: {OUTPUT_FILE}")
    print(f"   æ¡æ•°: {len(final_data)}")
    print("="*50)
    
    if final_data:
        print("\nğŸ‘€ æŠ½æŸ¥ç¬¬ä¸€æ¡ (å¿…é¡»æ˜¯æ•™ä¸»):")
        print(json.dumps(final_data[0], ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
