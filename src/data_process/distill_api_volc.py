import json
import os
from openai import OpenAI
from tqdm import tqdm
import concurrent.futures
import time

# ================= é…ç½®åŒº =================
# ä½ æä¾›çš„ç«å±±å¼•æ“é…ç½®
API_KEY = "718e7455-5e90-4d7b-8c47-7a2ac5c89611"
BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
MODEL_NAME = "deepseek-v3-2-251201"

# æ–‡ä»¶è·¯å¾„
INPUT_FILE = "data/processed/wuji_chunks.jsonl"
OUTPUT_FILE = "data/processed/train_dataset_dialogue.json"

# æ ¸å¿ƒäººç‰©è¿‡æ»¤ï¼ˆåªå¤„ç†è¿™äº›äººçš„ç‰‡æ®µï¼Œä¿è¯å«é‡‘é‡ï¼‰
TARGET_ROLES = ["èµµæ•", "å‘¨èŠ·è‹¥", "å°æ˜­", "æ®·ç¦»", "è››å„¿", "è°¢é€Š", "ä¹‰çˆ¶", "å¼ ä¸‰ä¸°", "æ¨é€", "èŒƒé¥", "ç­ç»", "é‡‘èŠ±å©†å©†"]

# æœ€å¤§å¤„ç†ç‰‡æ®µæ•°ï¼ˆè®¾ä¸º 500 è¶³å¤Ÿå‡‘é½å‡ ç™¾æ¡é«˜è´¨é‡å¯¹è¯äº†ï¼Œæƒ³è·‘å…¨æœ¬å¯ä»¥æ”¹å¤§ï¼‰
MAX_CHUNKS = 500
# =========================================

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

def extract_dialogue(chunk_text):
    """è°ƒç”¨ API æå–å¯¹è¯"""
    prompt = f"""
    ä½ æ˜¯ã€Šå€šå¤©å± é¾™è®°ã€‹å‰§æœ¬ä¸“å®¶ã€‚è¯·é˜…è¯»ç‰‡æ®µï¼Œæå–ã€ä»–äººã€‘ä¸ã€å¼ æ— å¿Œã€‘çš„ç²¾å½©å¯¹è¯ã€‚
    
    è¦æ±‚ï¼š
    1. è¾“å‡ºæ ‡å‡†çš„ JSON Listã€‚
    2. åŒ…å«ä¸¤ä¸ªå­—æ®µï¼š"instruction" (å¯¹æ–¹è¯´çš„è¯ï¼Œå¸¦ä¸Šäººåï¼Œå¦‚"èµµæ•ç¬‘é“ï¼š...") å’Œ "output" (å¼ æ— å¿Œçš„å›ç­”)ã€‚
    3. åªæå–ç›´æ¥å¯¹è¯ï¼Œå»é™¤æ— å…³æ—ç™½ã€‚
    4. å¦‚æœç‰‡æ®µä¸­æ²¡æœ‰æœ‰æ•ˆå¯¹è¯ï¼Œè¿”å›ç©ºåˆ—è¡¨ []ã€‚
    
    ç‰‡æ®µï¼š
    {chunk_text}
    """
    
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼éµå¾ªJSONæ ¼å¼çš„æ•°æ®æå–åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            # DeepSeek V3 å¬å¾—æ‡‚è¿™ä¸ªæŒ‡ä»¤ï¼Œä¼šå¼ºåˆ¶è¿”å› JSON
            response_format={"type": "json_object"}, 
            temperature=0.7
        )
        content = response.choices[0].message.content
        
        # è§£æ JSON
        data = json.loads(content)
        
        # å…¼å®¹å¤„ç†ï¼šæœ‰æ—¶å€™æ¨¡å‹ä¼šæŠŠ list åŒ…åœ¨ key é‡Œï¼Œæœ‰æ—¶å€™ç›´æ¥è¿”å› list
        if isinstance(data, dict):
            # å°è¯•æ‰¾å¯èƒ½çš„ key
            for key in ["dialogues", "conversations", "data", "pairs"]:
                if key in data and isinstance(data[key], list):
                    return data[key]
            # å¦‚æœæ²¡æ‰¾åˆ°å¸¸è§ keyï¼Œçœ‹çœ‹èƒ½ä¸èƒ½å¼ºè¡Œæ‹¿ values
            return []
        elif isinstance(data, list):
            return data
        return []
        
    except Exception as e:
        # print(f"API Error: {e}") # è°ƒè¯•æ—¶å¯ä»¥æ‰“å¼€
        return []

def process_chunk_wrapper(chunk):
    """åŒ…è£…å‡½æ•°ï¼Œç”¨äºçº¿ç¨‹æ± """
    text = chunk['text']
    
    # === æœ¬åœ°é¢„è¿‡æ»¤ (çœé’±å¤§æ³•) ===
    # 1. å¿…é¡»æœ‰å¼•å·
    if "â€œ" not in text: return []
    # 2. å¿…é¡»æœ‰æ ¸å¿ƒäººç‰©
    if not any(role in text for role in TARGET_ROLES): return []
    # 3. å¿…é¡»æœ‰æ— å¿Œ
    if "æ— å¿Œ" not in text and "æ•™ä¸»" not in text: return []
    
    # æ»¡è¶³æ¡ä»¶ï¼Œè°ƒç”¨ API
    raw_pairs = extract_dialogue(text)
    
    # æ ¼å¼åŒ–ä¸ºè®­ç»ƒæ•°æ®
    formatted_data = []
    for pair in raw_pairs:
        if "instruction" in pair and "output" in pair:
            # ç®€å•æ¸…æ´—
            instr = pair['instruction'].strip()
            out = pair['output'].strip()
            if len(instr) > 2 and len(out) > 1:
                formatted_data.append({
                    "instruction": instr,
                    "input": "",
                    "output": out,
                    "system": "ä½ ç°åœ¨æ˜¯å¼ æ— å¿Œï¼Œè¯·ä»¥æ˜æ•™æ•™ä¸»çš„èº«ä»½ï¼Œç”¨æ­¦ä¾ é£æ ¼å›ç­”ã€‚"
                })
    return formatted_data

def main():
    print(f"ğŸš€ å¯åŠ¨ API æé€Ÿæå–æ¨¡å¼ (Model: {MODEL_NAME})")
    
    # 1. è¯»å–ç‰‡æ®µ
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        all_chunks = [json.loads(line) for line in f]
    
    # é™åˆ¶æ•°é‡
    target_chunks = all_chunks[:MAX_CHUNKS]
    print(f"ğŸ“‚ å¾…æ‰«æç‰‡æ®µ: {len(target_chunks)} ä¸ª (å·²å¼€å¯æ ¸å¿ƒäººç‰©è¿‡æ»¤)")
    
    final_dataset = []
    
    # 2. å¹¶å‘æ‰§è¡Œ
    # å»ºè®®è®¾ä¸º 10-20ï¼Œå–å†³äºä½ çš„ API é™æµç­–ç•¥
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        # æäº¤ä»»åŠ¡
        futures = [executor.submit(process_chunk_wrapper, chunk) for chunk in target_chunks]
        
        # è¿›åº¦æ¡ç›‘æ§
        pbar = tqdm(total=len(futures), desc="âš¡ï¸ API æå–ä¸­")
        for future in concurrent.futures.as_completed(futures):
            results = future.result()
            if results:
                final_dataset.extend(results)
                pbar.set_postfix({"å·²è·æ•°æ®": len(final_dataset)})
            pbar.update(1)
            
    # 3. ä¿å­˜ç»“æœ
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ {len(final_dataset)} æ¡æ•°æ®...")
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_dataset, f, ensure_ascii=False, indent=2)
        
    print("="*50)
    print(f"ğŸ‰ å¤§åŠŸå‘Šæˆï¼")
    print(f"   æœ€ç»ˆæ•°æ®é›†: {OUTPUT_FILE}")
    print(f"   æ•°æ®é‡: {len(final_dataset)} æ¡")
    print("="*50)
    
    if final_dataset:
        print("\nğŸ‘€ è´¨é‡æŠ½æŸ¥:")
        print(json.dumps(final_dataset[:2], ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
